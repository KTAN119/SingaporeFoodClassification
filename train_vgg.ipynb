{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import Dataset, DataLoader \n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "\n",
    "class CrossEntropyLabelSmooth(nn.Module):\n",
    "    \"\"\"Cross entropy loss with label smoothing regularizer.\n",
    "    Reference:\n",
    "    Szegedy et al. Rethinking the Inception Architecture for Computer Vision. CVPR 2016.\n",
    "    Equation: y = (1 - epsilon) * y + epsilon / K.\n",
    "    Args:\n",
    "        num_classes (int): number of classes.\n",
    "        epsilon (float): weight.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes, epsilon=0.1, device='cpu'):\n",
    "        super(CrossEntropyLabelSmooth, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.epsilon = epsilon\n",
    "        self.device = device\n",
    "        self.logsoftmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            inputs: prediction matrix (before softmax) with shape (batch_size, num_classes)\n",
    "            targets: ground truth labels with shape (num_classes)\n",
    "        \"\"\"\n",
    "        log_probs = self.logsoftmax(inputs)\n",
    "        # targets = torch.zeros(log_probs.size()).scatter_(1, targets.unsqueeze(1).data, 1)# for mldg da\n",
    "        targets = torch.zeros(log_probs.size()).scatter_(1, targets.unsqueeze(1).data.cpu(), 1)#for zzd\n",
    "        targets = targets.to(self.device)\n",
    "        targets = (1 - self.epsilon) * targets + self.epsilon / self.num_classes\n",
    "        loss = (-Variable(targets) * log_probs).mean(0).sum()\n",
    "        return loss\n",
    "\n",
    "class TripletLoss(nn.Module):\n",
    "    \"\"\"Triplet loss with hard positive/negative mining.\n",
    "    Reference:\n",
    "    Hermans et al. In Defense of the Triplet Loss for Person Re-Identification. arXiv:1703.07737.\n",
    "    Code imported from https://github.com/Cysu/open-reid/blob/master/reid/loss/triplet.py.\n",
    "    Args:\n",
    "        margin (float): margin for triplet.\n",
    "    \"\"\"\n",
    "    def __init__(self, margin=0.3):\n",
    "        super(TripletLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "        self.ranking_loss = nn.MarginRankingLoss(margin=margin)\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            inputs: feature matrix with shape (batch_size, feat_dim)\n",
    "            targets: ground truth labels with shape (num_classes)\n",
    "        \"\"\"\n",
    "        n = inputs.size(0)\n",
    "        # Compute pairwise distance, replace by the official when merged\n",
    "        dist = torch.pow(inputs, 2).sum(dim=1, keepdim=True).expand(n, n)\n",
    "        dist = dist + dist.t()\n",
    "        dist.addmm_(1, -2, inputs, inputs.t())\n",
    "        dist = dist.clamp(min=1e-12).sqrt()  # for numerical stability\n",
    "        # For each anchor, find the hardest positive and negative\n",
    "        mask = targets.expand(n, n).eq(targets.expand(n, n).t())\n",
    "        dist_ap, dist_an = [], []\n",
    "        for i in range(n):\n",
    "            dist_ap.append(dist[i][mask[i]].max().unsqueeze(0))\n",
    "            dist_an.append(dist[i][mask[i] == 0].min().unsqueeze(0))\n",
    "        dist_ap = torch.cat(dist_ap)\n",
    "        dist_an = torch.cat(dist_an)\n",
    "        # Compute ranking hinge loss\n",
    "        y = torch.ones_like(dist_an)\n",
    "        loss = self.ranking_loss(dist_an, dist_ap, y)\n",
    "        return loss\n",
    "\n",
    "class CenterLoss(nn.Module):\n",
    "    \"\"\"Center loss.\n",
    "    \n",
    "    Reference:\n",
    "    Wen et al. A Discriminative Feature Learning Approach for Deep Face Recognition. ECCV 2016.\n",
    "    \n",
    "    Args:\n",
    "        num_classes (int): number of classes.\n",
    "        feat_dim (int): feature dimension.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes=10, feat_dim=2048, device='cpu'):\n",
    "        super(CenterLoss, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.feat_dim = feat_dim\n",
    "        self.device = device\n",
    "\n",
    "        self.centers = nn.Parameter(torch.randn(self.num_classes, self.feat_dim)).to(self.device)\n",
    "\n",
    "    def forward(self, x, labels):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: feature matrix with shape (batch_size, feat_dim).\n",
    "            labels: ground truth labels with shape (num_classes).\n",
    "        \"\"\"\n",
    "        batch_size = x.size(0)\n",
    "        distmat = torch.pow(x, 2).sum(dim=1, keepdim=True).expand(batch_size, self.num_classes) + \\\n",
    "                  torch.pow(self.centers, 2).sum(dim=1, keepdim=True).expand(self.num_classes, batch_size).t()\n",
    "        distmat.addmm_(1, -2, x, self.centers.t())\n",
    "\n",
    "        classes = torch.arange(self.num_classes).long()\n",
    "        classes = classes.to(self.device)\n",
    "        \n",
    "        labels = labels.unsqueeze(1).expand(batch_size, self.num_classes)\n",
    "        mask = labels.data.eq(classes.expand(batch_size, self.num_classes))\n",
    "        dist = []\n",
    "        for i in range(batch_size):\n",
    "            value = distmat[i][mask[i]]\n",
    "            value = value.clamp(min=1e-12, max=1e+12) # for numerical stability\n",
    "            dist.append(value)\n",
    "        dist = torch.cat(dist)\n",
    "        loss = dist.mean()\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FoodDataset(Dataset):\n",
    "    def __init__(self, file, transform=None, mode='train'):\n",
    "        self.transforms = transform\n",
    "        self.mode = mode\n",
    "        with open(file, 'r') as f:\n",
    "            self.image_list = f.readlines()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_list)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        label = None\n",
    "        if self.mode == 'train':\n",
    "            image, label = self.image_list[index].split('\\n')[0].split('\\t')\n",
    "            label = int(label)\n",
    "        else:\n",
    "            image = self.image_list[index].split('\\n')[0]\n",
    "        image = Image.open(image).convert('RGB')\n",
    "        image = self.transforms(image)\n",
    "        if self.mode == 'train':\n",
    "            return image, label\n",
    "        else:\n",
    "            return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms_train = transforms.Compose([\n",
    "                transforms.Resize((224, 224)),\n",
    "                transforms.RandomHorizontalFlip(p=0.5),\n",
    "                transforms.RandomVerticalFlip(p=0.5),\n",
    "                transforms.Pad(10, 10),\n",
    "                transforms.RandomRotation(45),\n",
    "                transforms.RandomCrop((224, 224)),\n",
    "                transforms.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.5),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "            ])\n",
    "\n",
    "transforms_test = transforms.Compose([\n",
    "                transforms.Resize((224, 224)),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(prediction, ground_truth):\n",
    "    num_correct = (np.array(prediction) == np.array(ground_truth)).sum()\n",
    "    return num_correct / len(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = FoodDataset('/media/ntu/volume2/home/s121md302_07/food/data/train.txt', transform=transforms_train)\n",
    "val_ds = FoodDataset('/media/ntu/volume2/home/s121md302_07/food/data/val.txt', transform=transforms_test)\n",
    "test_ds = FoodDataset('/media/ntu/volume2/home/s121md302_07/food/data/test.txt', transform=transforms_test)\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size=32, shuffle=True, num_workers=8)\n",
    "val_dl = DataLoader(val_ds, batch_size=32, shuffle=True, num_workers=8)\n",
    "test_dl = DataLoader(test_ds, batch_size=32, shuffle=True, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 5\n",
    "train_model = models.vgg19(pretrained=True)\n",
    "# train_model.fc = nn.Linear(512, num_classes)\n",
    "train_model.classifier[6] = nn.Linear(4096, num_classes)\n",
    "\n",
    "model_str = 'mobilenetv2'\n",
    "output_dir = 'checkpoint_' + model_str\n",
    "if output_dir and not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "ce_loss = CrossEntropyLabelSmooth(num_classes = num_classes, device = device)\n",
    "optimizer = torch.optim.Adam(train_model.parameters(), lr=0.0001)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:01<00:00,  8.06it/s]\n",
      "100%|██████████| 16/16 [00:01<00:00,  8.42it/s]\n",
      "100%|██████████| 16/16 [00:01<00:00,  8.43it/s]\n",
      "100%|██████████| 16/16 [00:01<00:00,  8.58it/s]\n",
      "100%|██████████| 16/16 [00:01<00:00,  8.56it/s]\n"
     ]
    }
   ],
   "source": [
    "for param in train_model.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in train_model.classifier.parameters():\n",
    "    param.requires_grad = True\n",
    "for i in range(5):\n",
    "    train_model.train()\n",
    "    train_model.to(device)\n",
    "    for img, label in tqdm(train_dl):\n",
    "        img = img.to(device)\n",
    "        label = label.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output= train_model(img) \n",
    "        loss = ce_loss(output, label) \n",
    "        loss.backward()\n",
    "        optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:03<00:00,  5.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[0] training accuracy: 0.434 training loss: 1.559e+00 Base Lr: 1.00000e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:01<00:00,  4.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5133333333333333    Epoch:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:03<00:00,  5.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[1] training accuracy: 0.584 training loss: 1.201e+00 Base Lr: 1.00000e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:03<00:00,  5.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[2] training accuracy: 0.676 training loss: 1.079e+00 Base Lr: 1.00000e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:03<00:00,  5.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[3] training accuracy: 0.746 training loss: 9.481e-01 Base Lr: 1.00000e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:03<00:00,  5.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[4] training accuracy: 0.766 training loss: 8.390e-01 Base Lr: 1.00000e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:03<00:00,  5.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[5] training accuracy: 0.82 training loss: 7.673e-01 Base Lr: 1.00000e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:03<00:00,  5.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[6] training accuracy: 0.846 training loss: 7.265e-01 Base Lr: 1.00000e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:03<00:00,  5.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[7] training accuracy: 0.878 training loss: 6.817e-01 Base Lr: 1.00000e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/16 [00:00<?, ?it/s]Exception ignored in: <function _releaseLock at 0x7fa748196f80>\n",
      "Traceback (most recent call last):\n",
      "  File \"/media/ntu/volume2/home/s121md302_07/anaconda3/envs/pytorch/lib/python3.7/logging/__init__.py\", line 221, in _releaseLock\n",
      "    def _releaseLock():\n",
      "KeyboardInterrupt\n",
      "100%|██████████| 16/16 [00:03<00:00,  4.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[8] training accuracy: 0.894 training loss: 6.435e-01 Base Lr: 1.00000e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:03<00:00,  4.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[9] training accuracy: 0.914 training loss: 6.149e-01 Base Lr: 1.00000e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:03<00:00,  5.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[10] training accuracy: 0.914 training loss: 6.076e-01 Base Lr: 1.00000e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:01<00:00,  4.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8133333333333334    Epoch:10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:03<00:00,  5.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[11] training accuracy: 0.93 training loss: 5.781e-01 Base Lr: 1.00000e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:03<00:00,  5.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[12] training accuracy: 0.962 training loss: 5.172e-01 Base Lr: 1.00000e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:03<00:00,  5.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[13] training accuracy: 0.968 training loss: 4.994e-01 Base Lr: 1.00000e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:03<00:00,  5.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[14] training accuracy: 0.93 training loss: 5.649e-01 Base Lr: 1.00000e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:03<00:00,  5.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[15] training accuracy: 0.936 training loss: 5.346e-01 Base Lr: 1.00000e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:03<00:00,  5.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[16] training accuracy: 0.946 training loss: 5.249e-01 Base Lr: 1.00000e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:03<00:00,  5.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[17] training accuracy: 0.954 training loss: 5.141e-01 Base Lr: 1.00000e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/16 [00:00<?, ?it/s]Exception ignored in: <function _releaseLock at 0x7fa748196f80>\n",
      "Traceback (most recent call last):\n",
      "  File \"/media/ntu/volume2/home/s121md302_07/anaconda3/envs/pytorch/lib/python3.7/logging/__init__.py\", line 221, in _releaseLock\n",
      "    def _releaseLock():\n",
      "KeyboardInterrupt\n",
      "100%|██████████| 16/16 [00:03<00:00,  5.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[18] training accuracy: 0.962 training loss: 4.751e-01 Base Lr: 1.00000e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:03<00:00,  5.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[19] training accuracy: 0.982 training loss: 4.687e-01 Base Lr: 1.00000e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:03<00:00,  5.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[20] training accuracy: 0.984 training loss: 4.597e-01 Base Lr: 1.00000e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:01<00:00,  4.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8    Epoch:20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:03<00:00,  5.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[21] training accuracy: 0.988 training loss: 4.376e-01 Base Lr: 1.00000e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:03<00:00,  5.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[22] training accuracy: 0.996 training loss: 4.304e-01 Base Lr: 1.00000e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▎        | 2/16 [00:00<00:06,  2.30it/s]"
     ]
    }
   ],
   "source": [
    "for param in train_model.parameters():\n",
    "    param.requires_grad = True\n",
    "epoch = 100\n",
    "highest_acc = {'epoch': 0, 'accuracy': 0}\n",
    "for ep in range(epoch):\n",
    "    train_model.train()\n",
    "    train_model.to(device)\n",
    "    count = 0\n",
    "    running_loss = 0.0\n",
    "    validation_loss = 0.0\n",
    "    output_list = []\n",
    "    ground_truth_list = []\n",
    "    for img, label in tqdm(train_dl):\n",
    "        img = img.to(device)\n",
    "        label = label.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output= train_model(img)\n",
    "        loss = ce_loss(output, label)\n",
    "        count += 1\n",
    "        prediction = torch.argmax(output, dim=1)\n",
    "        output_list.extend(prediction.detach().cpu())\n",
    "        ground_truth_list.extend(label.cpu())\n",
    "        running_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    scheduler.step()\n",
    "        \n",
    "    # if ep % 10 == 0:\n",
    "    #     torch.save(train_model.state_dict(), output_dir + '/' + model_str + '_' + str(ep) + '.pth')\n",
    "        \n",
    "    accuracy = evaluate(output_list, ground_truth_list)\n",
    "    print(f'Epoch[{ep}] training accuracy: {accuracy} '\n",
    "            f'training loss: {running_loss / count:.3e} Base Lr: {optimizer.param_groups[0][\"lr\"]:.5e}')\n",
    "\n",
    "    if ep % 10 == 0:\n",
    "        train_model.eval()\n",
    "        count = 0\n",
    "        output_list = []\n",
    "        ground_truth_list = []\n",
    "        for img, label in tqdm(val_dl):\n",
    "            with torch.no_grad():\n",
    "                img = img.to(device)\n",
    "                lbl = label.to(device)\n",
    "\n",
    "                output= train_model(img)\n",
    "\n",
    "                val_loss = ce_loss(output, lbl)\n",
    "\n",
    "                validation_loss += val_loss.item()\n",
    "                count += 1\n",
    "                prediction = torch.argmax(output, dim=1)\n",
    "                output_list.extend(prediction.detach().cpu())\n",
    "                ground_truth_list.extend(label)\n",
    "        accuracy = evaluate(output_list, ground_truth_list)\n",
    "        if accuracy > highest_acc['accuracy']:\n",
    "            highest_acc['accuracy'] = accuracy\n",
    "            highest_acc['epoch'] = ep\n",
    "        print(f'Accuracy: {accuracy}    Epoch:{ep}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(train_model.state_dict(), output_dir + '/' + model_str + '_' + 'final' + '.pth')\n",
    "print('highest_acc: {}  epoch: {}'.format(highest_acc['accuracy'], highest_acc['epoch']))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "59d55efc3955e58528d889e5fb54ed26f80617db376d5c1d40ac8e87cb109911"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
